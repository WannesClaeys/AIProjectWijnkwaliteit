---
title: 'AI Project: voorspellen wijnkwaliteit'
author: "Mano Mares & Wannes Claeys"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(data.table)
library(magrittr)
library(knitr)
library(readr)
library(reticulate)
library(MASS)
library(corrplot)
library(randomForest)

set.seed(42)

knitr::opts_chunk$set(echo = TRUE)

opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Opdracht

In deze opdracht is het de bedoeling om het klassieke Machine Learning proces te doorlopen a.d.h.v. een use case. Vanzelfsprekend hoort bij een model een voorspelling die vervolgens wordt geanalyseerd met echte data om de performantie/accuracy van het model te evalueren.

Use case: 
Een brouwerij in West-Vlaanderen wil graag de productie van wijnen optimaliseren door meer inzichten te vergaren over de impact van de verschillende wijn-kenmerken op de kwaliteit van de wijnen. Meer bepaald wil de brouwerij de kwaliteit van wijn voorspellen op basis van bepaalde kenmerken. Deze kenmerken zijn ondergebracht in 2 datasets, respectievelijk voor rode wijn en witte wijn. 

Deze datasets bevatten de fundamentele kenmerken die verantwoordelijk zijn voor het beïnvloeden van de kwaliteit van de wijn. Jullie doel is om, door middel van verschillende Machine Learning technieken en modellen de kwaliteit van de wijn te voorspellen.

Opmerking: als je in de voorbeeldcode 3 puntjes (...) tegenkomt, dan is het de bedoeling om de code aan te vullen.

# Runnen project

In dit project maken we gebruik van de programeer-taal "r". Binnen deze taal maken we gebruik van verschillende packages. Deze worden aangeroepen hierboven. Om deze packages succesvol te kunnen importeren, moeten deze geïnstalleerd worden. Dit kan via de console, waar men gebruik maakt van het commando "install.packages()". De packages die geïnstaleerd moeten worden zijn de volgende: data.table, magrittr, knitr, readr, reticulate, MASS, corrplot en randomForest.

# Data-Exploratie

Hier zullen we de gebruikte datasets bekijken, en beschrijven. Dit doen we om inzicht te krijgen in de data, voor we er algoritmen op loslaten.

## Wite wijn

In eerste instantie kijken we naar de data die beschikbaar is over de witten wijnen.

```{r}
data_winequality_white <- read.csv("Data - winequality-white.csv", header=TRUE, sep=";") %>% setDT
head(data_winequality_white)

```

Om te beginnen kijken we naar de kwaliteit van de witte wijnen. Dit doen we omdat we deze informatie willen kunnen leren voorspellen.

We zien dat over het algemeen de meeste wijnen vrij gemiddeld scoren. Ook valt op dat er geen wijnen zijn die lager als 3, of hoger als 9 scoren. Er zijn dus geen perfecte of extreem slechte scores beschikbaar. Dit kan later een probleem vormen bij het trainen van het algoritme. 

```{r}
qualityCountWhite <- table(data_winequality_white$quality)
barplot(qualityCountWhite, main="Qualtity of white wine",
   xlab="Quality")
summary(data_winequality_white$quality)
```

Nu kijken we naar het vaste zuur in de wijnen. Hierzien we dat deze relatief breed verspreid is. We merken op dat er twee pieken zijn. De eerste aan het begin, de tweede bij de hogere waarden.

```{r}
fixedAcidityWhite <- table(data_winequality_white$fixed.acidity)
d <- density(fixedAcidityWhite)
plot(d, main="Fixed acidity in the wine")
summary(data_winequality_white$fixed.acidity)

```
Als volgende kijken we naar het vluchtige zuur. Hier zien we 1 duidelijke piek aan het begin, me wat meer willekeurige data bij de hoge waarden.

```{r}
volatileAcidityWhite <- table(data_winequality_white$volatile.acidity)
plot(density(volatileAcidityWhite), main="Volatile acidity in the wine")
summary(data_winequality_white$volatile.acidity)

```
Ook bij het citroenzuur zien we een sterke pierk bij de beginwaarden, en meer rommelige data bij hogere waarden. We zien een tweede, veel kleinere piek rond 225.

```{r}
citricAcidWhite <- table(data_winequality_white$citric.acid)
plot(density(citricAcidWhite), main="Citric acid in the wine")
summary(data_winequality_white$citric.acid)
```

Als volgt kijken we naar de suikers in de wijn. Ook hier zien we een piek bij de kleine waarden, direct gevolgd door een tweede piek.

```{r}
residualSugarWhite <- table(data_winequality_white$residual.sugar)
plot(density(residualSugarWhite), main="Residual sugar in the wine")
summary(data_winequality_white$residual.sugar)
```

Het patroon zet zich voort bij de chlorides in de wijnen. Hier is de piek heel scherp.

```{r}
chloridesWhite <- table(data_winequality_white$chlorides)
d <- density(chloridesWhite)
plot(d, main="Chlorides in the wine")
summary(data_winequality_white$chlorides)
```

Nu kijken we naar het zwaveloxide in de wijnen. Er word een scheiding gemaakt tussen vrije en totale zwaveloxide in de wijnen.

Bij de vrije zwaveloxide zien we een piek aan het begin, en een  verdere uitspreiding naar de hogere waarden. Er is een kleine piek aan het einde van de spreiding bij 100.

```{r}
freeSulfurDioxideWhite <- table(data_winequality_white$free.sulfur.dioxide)
d <- density(freeSulfurDioxideWhite)
plot(d, main="Free sulfur dioxide in the wine")
summary(data_winequality_white$free.sulfur.dioxide)
```

Bij de totale zwaveloxide in de wijnen zien we een veel breedere verdeling, met een piek hoge piek, en een tweede piek bij de hogere waarden.

```{r}
totalSulfurDioxideWhite <- table(data_winequality_white$total.sulfur.dioxide)

d <- density(totalSulfurDioxideWhite)
plot(d, main="Total sulfur dioxide in the wine")
summary(data_winequality_white$total.sulfur.dioxide)
```

De dichtheid van de wijn heeft een heel sterke piek bij de lage waarden, rond 3.

```{r}
densityWhite <- table(data_winequality_white$density)
d <- density(densityWhite)
plot(d, main="Density of the wine")
summary(data_winequality_white$density)
```

De zuur waarden in de wijn heeft een sterke eerste piek, met een breede verdeling.

```{r}
phWhite <- table(data_winequality_white$pH)
d <- density(phWhite)
plot(d, main="PH vlaue of the wine")
summary(data_winequality_white$pH)
```

De sulfaat waarden in de wijnen hebben 2 pieken.

```{r}
sulphatesWhite <- table(data_winequality_white$sulphates)
d <- density(sulphatesWhite)
plot(d, main="Sulphate in the wine")
summary(data_winequality_white$sulphates)
```
Bij de alcohol percentages van de wijnen zien we opnieuw het patroon van een piek bij de lage waarden, en een verdere bredere verdeling.

```{r}
alcoholWhite <- table(data_winequality_white$alcohol)
d <- density(alcoholWhite)
plot(d, main="Alcohol percentage of the wine")
summary(data_winequality_white$alcohol)
```

## Rode wijn



```{r}
data_winequality_red <- read.csv("Data - winequality-red.csv", header=TRUE, sep=";") %>% setDT
head(data_winequality_red)

```
Bij de rode wijnen zien we dezelfde patronen opduiken als bij de witte wijnen. 

Ook bij de rode wijnen kijken we eerst naar de kwaliteit.
Hier zien we opnieuw dat over het algemeen de meeste wijnen vrij gemiddeld scoren. De laagste score blijft 3, maar de hoogste score is 8.


```{r}
qualityCountRed <- table(data_winequality_red$quality)
barplot(qualityCountRed, main="Qualtity of red wine",
   xlab="Quality")
summary(data_winequality_red$quality)
```

Als we kijken naar het vaste zuur in de wijnen, zien we dat deze relatief breed verspreid is. Ook hier zien we een eerste piek, en een kleinere tweede.

```{r}
fixedAcidityRed <- table(data_winequality_red$fixed.acidity)
d <- density(fixedAcidityRed)
plot(d, main="Fixed acidity in the red wine")
summary(data_winequality_red$fixed.acidity)

```
De vluchtige zuren hebben ook in de rode wijnen een stevige eerste piek, met een kleinere tweede piek.

```{r}
volatileAcidityRed <- table(data_winequality_red$volatile.acidity)
d <- density(volatileAcidityRed)
plot(d, main="Volatile acidity in the red wine")
summary(data_winequality_red$volatile.acidity)

```

Het citroenzuur is in de rode wijnen zeer breed verdeeld. Hoewel we een piek zien, is deze anders verdeeld, iets breder.

```{r}
citricAcidRed <- table(data_winequality_red$citric.acid)
d <- density(citricAcidRed)
plot(d, main="Citric acid in the red wine")
summary(data_winequality_red$citric.acid)
```

Bij de suikers zien we bij de rode wijnen een heel stevige piek, met wat ruis bij de hogere waarden.

```{r}
residualSugarRed <- table(data_winequality_red$residual.sugar)
d <- density(residualSugarRed)
plot(d, main="Residual sugar in the red wine")
summary(data_winequality_red$residual.sugar)
```

De chlorides in de rode wijnen hebben een eerste piek, gevolgd door ruis. In het ruis zijn er twee heuvels.

```{r}
chloridesRed <- table(data_winequality_red$chlorides)
d <- density(chloridesRed)
plot(d, main="Chlorides in the red wine")
summary(data_winequality_red$chlorides)
```
Nu kijken we naar de zwaveldioxides.

Bij de vrije zwaveldioxides zien we opnieuw een brede basis. Er is een piek bij de lage waarden.

```{r}
freeSulfurDioxideRed <- table(data_winequality_red$free.sulfur.dioxide)
d <- density(freeSulfurDioxideRed)
plot(d, main="Free sulfur dioxide in the red wine")
summary(data_winequality_red$free.sulfur.dioxide)
```
Bij het totale zwaveldioxide zien we de vorm van de vrije zwaveldioxide terugkeren.

```{r}
totalSulfurDioxideRed <- table(data_winequality_red$total.sulfur.dioxide)

d <- density(totalSulfurDioxideRed)
plot(d, main="Total sulfur dioxide in the red wine")
summary(data_winequality_red$total.sulfur.dioxide)
```

```{r}
densityRed <- table(data_winequality_red$density)
d <- density(densityRed)
plot(d, main="Density of the red wines")
summary(data_winequality_red$density)
```

```{r}
phRed <- table(data_winequality_red$pH)
d <- density(phRed)
plot(d, main="PH vlaue of the red wines")
summary(data_winequality_red$pH)
```

```{r}
sulphatesRed <- table(data_winequality_red$sulphates)
d <- density(sulphatesWhite)
plot(d, main="Sulphate in the wine")
summary(data_winequality_red$sulphates)
```
```{r}
alcoholRed <- table(data_winequality_red$alcohol)
d <- density(alcoholRed)
plot(d, main="Alcohol percentage of the wine")
summary(data_winequality_red$alcohol)
```

## Correlatie

Hier bekijken we de correlatie tussen de verschillende variabelen.

Bij de rode wijnen zien we een sterke correclatie tussen "vast zuur" en "citroen zuur", alsook tussen "vluchtig zuur" en "citroen zuur". Dit is logisch, want het gaat steeds over zuren.
Er is een minder sterke correlatie tussen vluchtig en vast zuur. Opnieuw lijkt dit logisch, omdat dit tegenstaande soorten zuur zijn.

Er is sterke correlatie tussen de PH waarden en de verschillende zuren. De PH waarden geven aan hoe sterk een zuur is, dus dit is te verklaren.

De twee zwavel dioxide waarden zijn ook sterk gecoreleerd aan elkaar. Opnieuw is dit logisch, het gaat namelijk over het totaal, en een sub categorie van zwavel dioxide.

```{r}
red_wine.cor = cor(data_winequality_red)
round(red_wine.cor, 2)
corrplot(red_wine.cor)
```

Bij de witte wijnen zien we een sterke correlatie tussen dichtheid en suiker. Daarnaast zijn ook de zwaveldioxide waarden sterk gecoreleerd. Dit met dezelfde reden als bij de rode wijnen.

Dichtheid en alcohol hebben ook een sterke correlatie, die kunnen we niet direct verklaren.

```{r}
white_wine.cor = cor(data_winequality_white)
round(white_wine.cor, 2)
corrplot(white_wine.cor)
```

## Conclusie Data-Exploratie

We zien dat bij beide datasets dezelfde patronen naarboven komen. Steeds een sterke piek bij lage waarden, met wat ruis en een tweede piek bij de hogere waarden. De locatie van de piek, en de ruis schuift wel op tussen rode en witte wijn.

Bij de correlatie zien we eigenlijk maar 1 echte gelijkenis terug keren. Namelijk de correlatie tussen de zwaveldioxide waarden.


# Data-Manipulatie

We kijken of er missende waarden zijn in de dataset van de witte wijnen.

```{r}
sum(is.na(data_winequality_white))
sum(is.null(data_winequality_white))
```
We kijken of er missende waarden zijn in de dataset van de rode wijnen.

```{r}
sum(is.na(data_winequality_red))
sum(is.null(data_winequality_red))
```

## Conclusie Data-Manipulatie

We doen niet aan datamanipulatie in dit project. Zoals hierboven te zien, zijn er geen ontbrekende waarden in de datasets. We zien het dus niet als noodzakelijk om hieraan veranderingen te maken.

Indien er toch ontbrekende waarden waren, hadden we de betreffende rijen uit de tabel kunnen halen met "na.omit" of met een null filter "Filter(Negate(is.null), dataset)".

We zien geen overbodige kolommen in de dataset. Er is geen data aanwezig die gevaar maakt voor een foutieve voorspelling. Daarom hebben we besloten om geen kolommen te verwijderen.

# Leeralgoritmen/Neurale Netwerken

-> Merk op: je kan dit probleem aanpakken als een regressieprobleem, maar ook als een classificatieprobleem. Let het verschil uit in de context van deze probleemstelling. Leg ook uit wat volgens jou de beste aanpak is.<br />
-> Selecteer nu 3 algoritmen: 2 algoritmen voor wat volgens jou de beste aanpak is, 1 algoritme voor de andere aanpak. <br /><br />

-> Start hieronder met het opstellen van jullie modellen en de voorspellingen voor elk van de 3 algoritmen. M.a.w.: aangezien jullie 3 algoritmen zullen gebruiken, zullen jullie 3 keer een model gebruiken en teven 3 keer voorspellen.<br />

-> Analyseer de resultaten van elk algoritme <br />
-> Concludeer over de de probleemstelling, het proces en de resultaten van elk model. Welk model past volgens jou het beste bij deze probleemstelling?


### Algoritme 1: LM() algoritme

**Witte wijn:**

De data wordt gesplitst in een trainingsset en testset. Vervolgens wordt het model gemaakt met de trainingsset.

```{r}
dt_white = sort(sample(nrow(data_winequality_white), nrow(data_winequality_white)*.8))
traindata_white <- data_winequality_white[dt_white,]
testdata_white <- data_winequality_white[-dt_white,]

model_white <- lm(quality ~., data = traindata_white)
```

Nu het model gemaakt is, kan met de testset voorspellingen worden gemaakt. Het verschil tussen de werkelijke kwaliteit en de voorspelde kwaliteit wordt ook weergegeven.

```{r}
prediction_quality_white <- predict(model_white, newdata = testdata_white)

result_white <- data.frame(testdata_white$quality, prediction_quality_white, margin_of_error = testdata_white$quality - prediction_quality_white)

head(result_white)
```
Om de kwaliteit van het model te evalueren, wordt de mean absolute error gebruikt. Hoe kleiner de error, hoe beter het model. 

```{r}
mae <- function(x, y) {mean(abs(y - x))}
```

```{r}
mae_white <- mae(prediction_quality_white, testdata_white$quality)
```

De mean absolute error voor witte wijn is `r mae_white`. Dit wil zeggen dat de voorspelde kwaliteit gemiddeld met `r round(mae_white, 2)` afwijkt van de werkelijke kwaliteit.



**Rode wijn:**

De data wordt gesplitst in een trainingsset en testset. Vervolgens wordt het model gemaakt met de trainingsset.

```{r}
dt_red = sort(sample(nrow(data_winequality_red), nrow(data_winequality_red)*.8))
traindata_red <- data_winequality_red[dt_red,]
testdata_red <- data_winequality_red[-dt_red,]

model_red <- lm(quality ~., data = traindata_red)
```

Nu het model gemaakt is, kan met de testset voorspellingen worden gemaakt. Het verschil tussen de werkelijke kwaliteit en de voorspelde kwaliteit wordt ook weergegeven.

```{r}
prediction_quality_red <- predict(model_red, newdata = testdata_red)

result_red <- data.frame(testdata_red$quality, prediction_quality_red, margin_of_error = testdata_red$quality - prediction_quality_red)

head(result_red)
```
Om de kwaliteit van het model te evalueren, wordt de mean absolute error gebruikt. Hoe kleiner de error, hoe beter het model. 

```{r}
mae <- function(x, y) {mean(abs(y - x))}
```

```{r}
mae_red <- mae(prediction_quality_red, testdata_red$quality)
```

De mean absolute error voor rode wijn is `r mae_red`. Dit wil zeggen dat de voorspelde kwaliteit gemiddeld met `r round(mae_red, 2)` afwijkt van de werkelijke kwaliteit.


### Algoritme 2: ...

-> Nu is het de bedoeling om na te denken over een 2de algoritme en daar een ML model rond te bouwen, te trainen, te testen en met voorspellingen te komen waarover je vervolgens kan reflecteren.<br />
-> MERK OP DAT BOVENSTAANDE VOORBEELDCODE ERG BEPERKT IS. DE CODE IS LOUTER ILLUSTRATIEF, MAAR GEEFT NIET WEER HOE BEKNOPT JULLIE TE WERK MOETEN GAAN. HET IS DE BEDOELING DAT JULLIE DUIDELIJKE CODE SCHRIJVEN, EN DEZE DOCUMENTEREN DOOR MIDDEL VAN UITLEG IN DIT DOCUMENT!



**Witte wijn:**
We kunnen opnieuw gebruik maken van dezelfde trainingsdataset en testdataset. Dit komt omdat we hier geen veranderingen op hebben uitgevoerd. Het eerste algoritme dat we gaan gebruiken om een model te maken is lda (Linear discriminant analysis). Zoals eerder aangegeven zullen we eerst onze dataset splitsen in een testdataset en een trainingsdataset. 80% stoppen we in de trainingsdata en 20% zullen we als testdata gebruiken. 

```{r}
head(dt_white)
dt_white_lda = sort(sample(nrow(data_winequality_white), nrow(data_winequality_white)*.8))
traindata_white_lda <- data_winequality_white[dt_white_lda,]
testdata_white_lda <- data_winequality_white[-dt_white_lda,]
head(traindata_white_lda$quality)
model_white_lda <- lda(quality ~., data = traindata_white_lda)
```

We hebben nu een model klaarstaan, dit kunnen we vervolgens gebruiken om een voorspelling te maken op de wijn. 

```{r}
prediction_quality_white_lda <- predict(model_white_lda, newdata = testdata_white_lda)
result_white_lda <- data.frame(testdata_white_lda$quality, prediction_quality_white_lda$class)
head(prediction_quality_white_lda$class, margin_of_error = testdata_white_lda$quality - prediction_quality_white_lda$class)
head(result_white_lda)
```

De functie predict kan aan de hand van het model een voorspelling maken op, in dit geval de wijnkwaliteit. Anders dan bij het 'lm' algoritme is dat er hier ronde getallen komen uit de prediction. Dit komt volgens mij omdat het 'lda' algoritme gebruik maakt van distincte categorieën. Uiteraard zijn de waarden die uit de voorspelling komen minder precies, maar blijft na het vergelijken met de testdata nog vrij accuraat waardoor dit algoritme zeker bruikbaar is. Het 'lda' lijkt ons wel echter niet de perfecte oplossing om de wijnkwaliteit te voorspellen omdat in dit geval mogelijks te veel zal worden afgerond waardoor je een iets minder accuraat antwoord krijgt. 

**Rode wijn:**

We kunnen vervolgens hetzelfde uitvoeren bij de rode wijn

```{r}
dt_red_lda = sort(sample(nrow(data_winequality_red), nrow(data_winequality_red)*.8))
traindata_red_lda <- data_winequality_red[dt_red_lda,]
testdata_red_lda <- data_winequality_red[-dt_red_lda,]
head(traindata_red_lda$quality)
model_red_lda <- lda(quality ~., data = traindata_red_lda)
```

Het model staat nu klaar voor de rode wijn. Nu zullen we met dit model de voorspelling kunnen maken met de predict-functie.

```{r}
prediction_quality_red_lda <- predict(model_red_lda, newdata = testdata_red_lda)
result_red_lda <- data.frame(testdata_red_lda$quality, prediction_quality_red_lda$class)
head(prediction_quality_white_lda$class, margin_of_error = testdata_red_lda$quality - prediction_quality_red_lda$class)
summary(prediction_quality_red_lda$class)
```

### Algoritme 3: ...

-> Nu is het de bedoeling om na te denken over een 3de algoritme en daar een ML model rond te bouwen, te trainen, te testen en met voorspellingen te komen waarover je vervolgens kan reflecteren


**Witte wijn:**

De tabel moet nu dus opnieuw opgesplitst worden in een testdataset en en traingsdataset.

```{r}
dt_white_rf = sort(sample(nrow(data_winequality_white), nrow(data_winequality_white)*.8))
traindata_white_rf = data_winequality_white[dt_white_rf,]
testdata_white_rf = data_winequality_white[-dt_white_rf,]
```

Vervolgens zal het model moeten worden aangemaakt. 

```{r}
model_white_rf <- randomForest(quality ~., data= traindata_white_rf)
summary(model_white_rf$quality)
prediction_quality_white_rf <- predict(model_white_rf)
summary(prediction_quality_white_rf)
head(prediction_quality_white_rf, margin_of_error = testdata_white_nrf$quality)
```
**Rode wijn:**

```{r}
dt_red_rf = sort(sample(nrow(data_winequality_red), nrow(data_winequality_red)*.8))
traindata_red_rf = data_winequality_red[dt_red_rf,]
testdata_red_rf = data_winequality_red[-dt_red_rf,]
```



```{r}
model_red_rf <- randomForest(quality~., data = traindata_red_rf)
```

Vervolgens kunnen we met het model een voorspelling maken aan de hand van de predict-functie.

```{r}
prediction_quality_red_rf <- predict(model_red_rf)
summary(prediction_quality_red_rf)
head(prediction_quality_red_rf, margin_of_error = testdata_red_rf$quality - prediction_quality_red_rf)
```

### Conclusie

We merken op dat het gebruik van de drie verschillende leer algoritmes steeds vrij acurate voorspellingen geeft. Het verschil in de algoritmes zorgt wel voor andere soorten predicties. 

Zo zien we dat het tweede algoritme enkel distincte groepen voorspelt. Dit is meer in lijn met de dataset, waar enkel gehele getallen mogelijk zijn. 

De twee andere algoritmes voorspellen eerder op een schaal. Als we hier drempel waarden zouden voorzien tussen de waarden, kunnen we deze omzetten naar gehele getallen. In dit gevel lijkt het ons de logische keuze om te gaan voor drempel waarden zoals de afrondingsregels. Zo zien we dat ook deze algoritmen steeds een redelijk correct voorspelling hebben.

De keuze voor het algoritme zou op basis van de dataset dus op algoritme 2 moeten vallen. Zoals eerder gezegd is het dus wel mogelijk om de andere datasets te gebruiken met afronding.

### Bronnen

[1] Gebruik van "Na-omit":
https://www.statology.org/na-omit-in-r/

[2] Voor onderzoek naar verschillende algoritmes:
https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/

[3] Info over Random Forest algoritme:
https://www.geeksforgeeks.org/random-forest-approach-for-regression-in-r-programming/?ref=rp

[4] Info over LDA algoritme:
https://www.r-bloggers.com/2021/05/linear-discriminant-analysis-in-r/